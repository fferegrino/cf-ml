{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cb43bc-6457-42a1-9467-23f6021d59da",
   "metadata": {},
   "source": [
    "# Precio de autom√≥viles usados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b205551-4d5e-4048-bc6b-3ddc1297c2bc",
   "metadata": {},
   "source": [
    "Imaginen ustedes que tienen un amigo que quiere vender un autom√≥vil, pero no est√° muy seguro de cu√°nto cobrar por √©l. ¬øQu√© har√≠as?\n",
    "\n",
    "Este es el problema que Aditya se encontr√≥, entonces lo que hizo fue hacer web scraping (dedscargar informaci√≥n de la web) para obtener informaci√≥n de un sitio de venta de autom√≥viles en donde est√°ban listadas un mont√≥n de caracter√≠sticas y el precio final al que cada uno de ellos fue vendido. \n",
    "\n",
    " > ‚ùì ¬øC√≥mo es que nosotros podemos ayudar?\n",
    " \n",
    "Accede a el dataset en el archivo `cars.csv`, puedes ver el dataset original [aqu√≠](https://www.kaggle.com/adityadesai13/used-car-dataset-ford-and-mercedes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9766b-8800-4fdb-a6a0-5ab9f280e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990c355-15b1-416a-b3e1-4fa6691fd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cb2a25-d541-4525-bf5f-e537dd8fa878",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec7305-c0e2-4a31-94f5-16282558295f",
   "metadata": {},
   "source": [
    " > ‚ÅâÔ∏è Y las m√©tricas de evaluaci√≥n ‚Äì en la regresi√≥n no tenemos muchas opciones, podemos usar RMSE o MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c4b7d-d875-4879-9493-2c84ec655b45",
   "metadata": {},
   "source": [
    "## An√°lisis Exploratorio de Datos\n",
    "\n",
    "Antes de meternos de fondo a la etapa del modelado, vamos a generar un reporte usando la biblioteca [Pandas Profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1288b042-8150-45e0-b70a-fd3e6e3678c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(cars, title=\"Raw Car Dataset Analysis\", explorative=True)\n",
    "profile.to_file(\"cars-report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718dd800-178e-446d-86ca-0baff26472b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd() + \"/cars-report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f98934-501f-4642-abcc-92940c0483a5",
   "metadata": {},
   "source": [
    "## Elimina los duplicados\n",
    "\n",
    "Una de las grandes advertencias provistas por nuestro reporte es que existen duplicados en el dataset, as√≠ que vamos a comenzar con eso.\n",
    "\n",
    " > üòâ Lee la documentaci√≥n de `drop_duplicates` para ver qu√© hacen los distintos par√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f6fe37-82d9-4409-85ad-809be82b26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = cars.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5b17b-84e1-4687-b1bf-2a617305b73a",
   "metadata": {},
   "source": [
    "## Divide el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b96713-7f64-4a50-b1ac-2c540f623f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b23d6-0eb4-49bd-9fbf-d2fcb1ba1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest, test = train_test_split(cars, test_size=0.2, shuffle=True) # 20% of 100 = 20\n",
    "train, val = train_test_split(rest, test_size=0.25, shuffle=True) # 25% of 80 = 20\n",
    "distributions = np.array([len(train), len(val), len(test)])\n",
    "\n",
    "print(distributions)\n",
    "print(distributions / len(cars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed93ab-f6da-4040-8737-e67c21d37aad",
   "metadata": {},
   "source": [
    "## *Feature engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60020e53-4f20-4d95-9814-2d610b345f74",
   "metadata": {},
   "source": [
    "### One-hot encode categorical variables\n",
    "\n",
    "Necesitamos una manera de pasar de una variable categ√≥rica a n√∫meros, por ejemplo, tenemos en nuestro dataset una columna llamada *\"maker\"*, que se traduce a la constructora del autom√≥vil: \"bnw\", \"ford\", \"audi\"...\n",
    "\n",
    "Debemos encontrar una forma de convertirlos a n√∫meros que nuestro algoritmo pueda usar para entrenar nuestro modelo, a este proceso se le llama  *\"encoding\"* (o codificaci√≥n).\n",
    "\n",
    " > üìπ tengo un video sobre tipos de variables: [https://www.youtube.com/watch?v=SAWsQ3QmmJE](https://www.youtube.com/watch?v=SAWsQ3QmmJE)\n",
    " \n",
    "Una forma de codificar variables categ√≥ricas es usando *One-Hot Encoding*, que expandir√° nuestra √∫nica columna categ√≥rica en un vector (que podemos representar en forma de columnas) de 1 y 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0dd85-196e-4b59-9b3e-a05f7d5a9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "maker_encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965cb299-2f5f-4464-ae4e-20d4ea08dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "maker_encoder.fit(train[[\"maker\"]])\n",
    "mkr = maker_encoder.transform(train[[\"maker\"]]).todense()\n",
    "\n",
    "print(mkr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddcc97-02e1-46cb-b5a7-52f98dbbbc9a",
   "metadata": {},
   "source": [
    "Para revisar las categor√≠as, podemos usar la propieddad `categories_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8654358-8fdb-48f3-9bf8-0af71c028d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mkr, columns=maker_encoder.categories_, index=train[[\"maker\"]].index)\n",
    "df[\"actual\"] = train[[\"maker\"]]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13397377-abf6-48af-b5f5-523e46bc809e",
   "metadata": {},
   "source": [
    "#### üö® `pd.get_dummies` ?\n",
    "\n",
    "Para hacer *machine learning* no te recomiendo usar `pd.get_dummies` porque no es robusto ante datos faltantes y no preserva el estado, por ejemplo, cuando recibimos un registro para predecir en producci√≥n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6042-64bf-45da-bd28-21abc53279f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_maker = \"audi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95114976-9d4a-4ba9-b120-ea43926bb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies([test_maker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd5b6e-b1cd-4b4f-80e8-d2a86362facb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maker_encoder.transform([[test_maker]]).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0ea6a3-fc95-407d-81f4-2e416e8ea9ae",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "\n",
    "Existen algoritmos que basan su entrenamiento en √∫nicamente n√∫meros, sin contexto alguno. Algunos de ellos tienden a otorgar mayor importancia a aquellos n√∫meros cuyo valor es m√°s grande. Una apuesta segur es escalar los valores de una caracter√≠stica de tal modo que todos se encuentren en la misma escala, pero preservando las distancias relativas ente ellos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157994de-9c8f-4276-8261-9ce7123c3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "scaler = MaxAbsScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7755066-498e-4f03-96e9-0b9bd395b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train[[\"mileage\"]])\n",
    "scaled = scaler.transform(train[[\"mileage\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a80f5d-3d09-4731-aa8a-407927fb44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = pd.DataFrame({\"mileage\": train[\"mileage\"].values, \"scaled\": scaled.squeeze() })\n",
    "values.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4401941d-0b0d-412f-a2e7-45517d5ae970",
   "metadata": {},
   "source": [
    "# Artefactos\n",
    "\n",
    "Hemos visto una diversidad de herramientas que nos sirven para transformar una de nuestras observaciones del munddo real, como el di√°logo emitido por una persona o un autom√≥vil, a un grupo de n√∫meros. \n",
    "\n",
    "Cosas como el `OneHotEncoder`, `CountVectorizer` y `MaxAbsScaler` forman parte de este conjunto de herramientas que, una vez preparadas con `fit`, debemos preservar para poder re-usarlas en producci√≥n. Estas herramientas son conocidas como artefactos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d55cee-c1a8-41b6-ba0c-6ed352a6ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"scaler.pickle\", \"wb\") as wb:\n",
    "    pickle.dump(scaler, wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba859abc-68c7-4ff3-b81d-c9248ea3476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scaler.pickle\", \"rb\") as rb:\n",
    "    scaler_loaded = pickle.load(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf252e1-c538-4025-bb7d-1c3c7a6c4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_loaded.transform([[400]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e553d9-045a-40e8-af7d-22896065c282",
   "metadata": {},
   "source": [
    "# Pipelines  \n",
    "\n",
    "A lo largo del modelado creamos un mont√≥n de *artefactos* que debemos conservar para asegurarnos de que usaremos los mismos valores, par√°metros e hiperpar√°metros. Una alternativa ser√≠a guardar cada uno de los `OneHotEncoder`, `MinMaxScaler` y cualquier otro objeto que creamos para entrenar nuestro modelo de ML.\n",
    "\n",
    "Otra forma de hacerlo, un poco m√°s organizada es hacer uso de un `Pipeline` de *scikit learn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98b2b7-154f-449e-a3b8-c7dbd5509581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config\n",
    "\n",
    "# One-Hot encode maker, transmission y fuelType\n",
    "one_hot_encode = ColumnTransformer([\n",
    "    (\n",
    "        'one_hot_encode', # Nombre de la transformaci√≥n\n",
    "        OneHotEncoder(sparse_output=False), # Transformaci√≥n a aplicar\n",
    "        [\"maker\", \"transmission\", \"fuelType\"] # Columnas involucradas\n",
    "    )\n",
    "])\n",
    "\n",
    "# Robust encode mileage\n",
    "robust_encoding = ColumnTransformer([\n",
    "    ('robust_encoding', RobustScaler(), [\"mileage\"])\n",
    "])\n",
    "\n",
    "# Impute and standard scale mpg and tax\n",
    "impute_and_scale = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', MinMaxScaler())\n",
    "])\n",
    "\n",
    "standard_scaling = ColumnTransformer([\n",
    "    ('standard_scaling', impute_and_scale, [\"mpg\", \"tax\"])\n",
    "])\n",
    "\n",
    "# Just pass year and engineSize\n",
    "passthrough = ColumnTransformer([('passthrough', 'passthrough', ['year', \"engineSize\"])])\n",
    "\n",
    "# Ensambla todo el pipeline\n",
    "pipe = Pipeline([\n",
    "    (\n",
    "        'features',\n",
    "        FeatureUnion([\n",
    "            ('one_hot_encode', one_hot_encode),\n",
    "            ('robust_encoding', robust_encoding),\n",
    "            ('just_passs', passthrough),\n",
    "            ('scale_and_impute', standard_scaling)\n",
    "        ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086bdc2-acfb-4955-b4dc-0f9bf2926862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0bc1c-df3d-4180-91d6-abaa192c62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train)\n",
    "\n",
    "pd.DataFrame(pipe.transform(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fb447-730e-4f15-ac6d-9ff1f965a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pipe.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31369585-f66f-45e4-9781-63fef7933bc1",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77297c47-2cca-47b9-99ee-15b5f8f957e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84398267-896b-4366-b5cf-75688b37ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f38178-8fd7-4d65-bf78-1e7effcf5592",
   "metadata": {},
   "source": [
    "Creamos otro pipeline, que incluya nuestro modelo de regresi√≥n elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547b341-153a-4aa7-9a72-1a2aef768714",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_pipeline = Pipeline([\n",
    "    ('feature', pipe),\n",
    "    ('estimator', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f194c0-177e-437c-95bb-d3eeaf886222",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicting_pipeline.fit(train, train['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8175780-e6e0-44b7-8c0c-3893851033bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = predicting_pipeline.predict(train)\n",
    "val_pred = predicting_pipeline.predict(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b4971f-5828-4a7f-87c9-5b5d7c45b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'real':val['price'], 'predicted':val_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc612046-49dd-49b6-9d24-955dbfc6ab70",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d24226-17f7-4a92-9d52-404689967af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81505b-b5f1-4cc8-8543-5fd5a70f11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = mean_absolute_error(train['price'], train_pred)\n",
    "val_mse = mean_absolute_error(val['price'], val_pred)\n",
    "\n",
    "print(f\"Entrenamiento MSE: {train_mse:2.02f}\\n\"\n",
    "      f\"Validaci√≥n MSE:    {val_mse:2.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3d7b4-ff7c-4f0b-b417-b3d382dc5cfe",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n en los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db9521-5356-4a06-a98c-08ffb7546fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = predicting_pipeline.predict(test)\n",
    "test_mse = mean_absolute_error(test['price'], test_pred)\n",
    "\n",
    "print(f\"Prueba MSE: {test_mse:2.02f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ff1f3-8553-4b20-bf6b-df3a940d54af",
   "metadata": {},
   "source": [
    "# Guarda el pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852e3da-b16f-4856-a1d6-c64e27842d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(predicting_pipeline, 'car-prices.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4304ab-39ed-4c27-80ef-8cca512ebbe4",
   "metadata": {},
   "source": [
    "## Prediciendo en nuestro propio auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cae166-fcb8-4c87-a962-35e50f7998ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_pipeline = load('car-prices.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d1927-ee6c-468b-9337-048af079b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "maker = \"ford\"\n",
    "model = \"focus\"\n",
    "year = 2020\n",
    "transmission = \"Manual\"\n",
    "mileage = 50\n",
    "fuelType = \"Petrol\"\n",
    "tax = 100\n",
    "mpg = 30\n",
    "engineSize = 1.5\n",
    "\n",
    "mi_autom√≥vil = pd.DataFrame({\n",
    "    \"maker\": [maker], \"model\": [model], \"year\": [year], \"transmission\": [transmission], \n",
    "    \"mileage\": [mileage], \"fuelType\": [fuelType], \"tax\": [tax], \"mpg\": [mpg], \"engineSize\": [engineSize],\n",
    "})\n",
    "\n",
    "price = saved_pipeline.predict(mi_autom√≥vil).squeeze()\n",
    "\n",
    "print(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027e274a-a651-46ba-8fa2-b4d8739887d1",
   "metadata": {},
   "source": [
    "## De tarea... \n",
    "\n",
    " - Creamos un modelo para todas las constructoras, ¬øvaldr√≠a la pena crear un modelo independiente para cada una? ‚Äì int√©ntalo y ve si los resultados mejoran.\n",
    " - Utiliza otro modelo, tal vez [XGBoost](https://xgboost.readthedocs.io/en/stable/) para ver si te da mejores resultados\n",
    " - ¬øSabes Flask, FastAPI, o Django? pon tu modelo en una API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212295b6-445d-4f5b-9278-8153729f0a1e",
   "metadata": {},
   "source": [
    "## Para aprender m√°s  \n",
    "\n",
    " - √âchale un ojo a mi video sobre [tipos de variables](https://www.youtube.com/watch?v=SAWsQ3QmmJE)\n",
    " - Conoce [cu√°ndo escalar y cuando normalizar](https://datascience.stackexchange.com/questions/45900/when-to-use-standard-scaler-and-when-normalizer) tus datos\n",
    " - Revisa la [documentaci√≥n de sklearn](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) referente a los diferentes escaladores\n",
    " - Aprende [cu√°ndo es v√°lido eliminar outliers](https://statisticsbyjim.com/basics/remove-outliers/) (valores extremos)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043ade40-3968-4601-9559-4356bdf36a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
