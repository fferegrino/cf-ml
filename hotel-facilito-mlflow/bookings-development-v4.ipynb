{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68000e2a-e351-4946-b982-25dc17c76106",
   "metadata": {},
   "source": [
    "# Hotel Facilito – Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3528de5-5762-4ca6-98ec-2033175fb500",
   "metadata": {},
   "source": [
    "![](./images/header.png)\n",
    "\n",
    "Estábamos creando un modelo para predecir (y calcular las probabilidades) de que un cliente cancelara su reserva de hotel. El resultado es el código que tenemos a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78980f6-b4c6-4b2d-8bb1-261bd091ae97",
   "metadata": {},
   "source": [
    "## Lee y limpia inicialmente los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61451c38-e25a-44f6-9ed5-068ea6811e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61187393-4677-4f03-a3dd-43be2ef77740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file):\n",
    "    hotel_bookings = pd.read_csv(file)\n",
    "\n",
    "    # Remove personal information of customers\n",
    "    hotel_bookings = hotel_bookings.drop(['name', 'email', 'phone-number', 'credit_card'], axis=1)\n",
    "    \n",
    "    # Avoid data leakage\n",
    "    hotel_bookings = hotel_bookings.drop(['reservation_status', 'reservation_status_date'], axis=1)\n",
    "\n",
    "    # Convert objects to strings\n",
    "    object_columns = hotel_bookings.select_dtypes('object').columns\n",
    "    hotel_bookings[object_columns] = hotel_bookings[object_columns].astype(str)\n",
    "\n",
    "    return hotel_bookings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a338899-2d62-4a4a-87d3-9c84f76d7810",
   "metadata": {},
   "source": [
    "## Separa columnas y divide el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f24c75-b3ae-4a84-b735-513591f70542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(bookings_dataset, train_proportion, test_proportion):\n",
    "    is_canceled = bookings_dataset['is_canceled'].copy()\n",
    "    hotel_data = bookings_dataset.drop(['is_canceled'], axis=1)\n",
    "\n",
    "    original_count = len(bookings_dataset)\n",
    "    training_size = int(original_count * train_proportion)\n",
    "    test_size = int((1 - train_proportion) * test_proportion * training_size)\n",
    "    \n",
    "    train_x, rest_x, train_y, rest_y = train_test_split(hotel_data, is_canceled, train_size=training_size)\n",
    "    test_x, validate_x, test_y, validate_y = train_test_split(rest_x, rest_y, train_size=test_size)\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'dataset_size': original_count,\n",
    "        'training_set_size': len(train_x),\n",
    "        'validate_set_size': len(validate_x),\n",
    "        'test_set_size': len(test_x)\n",
    "    })\n",
    "\n",
    "    return (train_x, train_y), (validate_x, validate_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de1c87-3b69-48c4-9f5e-09e3c314757c",
   "metadata": {},
   "source": [
    "## Creación del pipeline de featurización y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45bc83-aa51-421e-b4b9-1fbf78f13633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, Binarizer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def build_pipeline():\n",
    "    # One-hot encoder\n",
    "    internal_one_hot_encoding = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    columns_to_encode = [\n",
    "        \"hotel\",\n",
    "        \"meal\", \n",
    "        \"distribution_channel\", \n",
    "        \"reserved_room_type\", \n",
    "        \"assigned_room_type\", \n",
    "        \"customer_type\"\n",
    "    ]\n",
    "\n",
    "    mlflow.log_param('one_hot_encoded_columns', columns_to_encode)\n",
    "    encoder_params = internal_one_hot_encoding.get_params()\n",
    "    mlflow.log_params({\n",
    "        f\"encoder__{key}\": value for key, value in encoder_params.items()\n",
    "    })\n",
    "    \n",
    "    one_hot_encoding = ColumnTransformer([\n",
    "        (\n",
    "            'one_hot_encode',\n",
    "            internal_one_hot_encoding,\n",
    "            columns_to_encode\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Binarizer\n",
    "    internal_binarizer = Binarizer()\n",
    "    columns_to_binarize = [\n",
    "        \"total_of_special_requests\", \n",
    "        \"required_car_parking_spaces\", \n",
    "        \"booking_changes\", \n",
    "        \"previous_bookings_not_canceled\", \n",
    "        \"previous_cancellations\",\n",
    "    ]\n",
    "    internal_encoder_binarizer = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "    \n",
    "    binarizer = ColumnTransformer([\n",
    "        (\n",
    "            'binarizer',\n",
    "            internal_binarizer,\n",
    "            columns_to_binarize\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    one_hot_binarized = Pipeline([\n",
    "        (\"binarizer\", binarizer),\n",
    "        (\"one_hot_encoder\", internal_encoder_binarizer),\n",
    "    ])\n",
    "\n",
    "    # Scaler\n",
    "    internal_scaler = RobustScaler()\n",
    "    columns_to_scale = [\"adr\"]\n",
    "    \n",
    "    scaler = ColumnTransformer([\n",
    "        (\"scaler\", internal_scaler, columns_to_scale)\n",
    "    ])\n",
    "\n",
    "    # Passthrough columns\n",
    "    pass_columns = [\n",
    "        \"stays_in_week_nights\",\n",
    "        \"stays_in_weekend_nights\",\n",
    "    ]\n",
    "    \n",
    "    passthrough = ColumnTransformer([\n",
    "        (\n",
    "            \"pass_columns\",\n",
    "            \"passthrough\",\n",
    "            pass_columns\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Full pipeline\n",
    "    feature_engineering_pipeline  = Pipeline([\n",
    "        (\n",
    "            \"features\",\n",
    "            FeatureUnion([\n",
    "                ('categories', one_hot_encoding),\n",
    "                ('binaries', one_hot_binarized),\n",
    "                ('scaled', scaler),\n",
    "                ('passthrough', passthrough)\n",
    "            ])\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # Machine learning model\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    \n",
    "    model_params = model.get_params()\n",
    "    mlflow.log_params({\n",
    "        f\"model__{key}\": value for key, value in model_params.items()\n",
    "    })\n",
    "\n",
    "    # Full pipeline\n",
    "    final_pipeline = Pipeline([\n",
    "        (\"feature_engineering\", feature_engineering_pipeline),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    return final_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82c440-dd89-47d5-b7d5-8a2630844fb7",
   "metadata": {},
   "source": [
    "## Model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95411f0-3b48-41f2-bc2f-505ac50cf293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "def model_training_validation(final_pipeline, train_x, train_y, validate_x, validate_y):\n",
    "    final_pipeline.fit(train_x, train_y)\n",
    "\n",
    "    train_pred_y = final_pipeline.predict(train_x)\n",
    "    validate_pred_y = final_pipeline.predict(validate_x)\n",
    "\n",
    "    train_accuracy = accuracy_score(train_pred_y, train_y)\n",
    "    train_recall = recall_score(train_pred_y, train_y)\n",
    "    \n",
    "    validate_accuracy = accuracy_score(validate_pred_y, validate_y)\n",
    "    validate_recall = recall_score(validate_pred_y, validate_y)\n",
    "\n",
    "    print('Train accuracy', train_accuracy)\n",
    "    print('Train recall', train_recall)\n",
    "    \n",
    "    print('Validate accuracy', validate_accuracy)\n",
    "    print('Validate recall', validate_recall)\n",
    "\n",
    "    metrics = {\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_recall': train_recall,\n",
    "        'validate_accuracy': validate_accuracy,\n",
    "        'validate_recall': validate_recall,\n",
    "    }\n",
    "\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    return final_pipeline, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8e769-65dd-483a-b59c-f4098c4a284e",
   "metadata": {},
   "source": [
    "## Full training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b7f4e-b9af-4737-bdfc-db5b39281ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "def full_training_run():\n",
    "\n",
    "    mlflow.set_experiment(\"/hotel-facilito/BookingCancellations\")\n",
    "    with mlflow.start_run() as run:\n",
    "        raw_dataset = load_data(\"data/hotel_bookings_training.csv\")\n",
    "        \n",
    "        training_data, validate_data, test_data = split_dataset(raw_dataset, train_proportion=0.6, test_proportion=0.5)\n",
    "        \n",
    "        training_pipeline = build_pipeline()\n",
    "        \n",
    "        training_pipeline, metrics = model_training_validation(\n",
    "            training_pipeline,\n",
    "            train_x=training_data[0],\n",
    "            train_y=training_data[1],\n",
    "            validate_x=validate_data[0],\n",
    "            validate_y=validate_data[1]\n",
    "        )\n",
    "\n",
    "        dump(training_pipeline, \"inference_pipeline.joblib\")\n",
    "        mlflow.log_artifact('inference_pipeline.joblib')\n",
    "\n",
    "        signature = infer_signature(training_data[0], training_data[1])\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=training_pipeline,\n",
    "            artifact_path=\"cancellations-model\",\n",
    "            signature=signature,\n",
    "            registered_model_name=\"CancellationsModel\",\n",
    "        )\n",
    "\n",
    "    return training_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5e6312-7c92-4a91-89ae-2e359a8d08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fb0a6-940f-4722-b2d3-8b4b22e7d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf mlruns/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85c693-8065-465b-ad97-77111921c085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
